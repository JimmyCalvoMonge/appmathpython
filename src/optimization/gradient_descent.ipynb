{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Finding the minima of general functions represents an extremely important task in many use cases of applied mathematics. The most notable example comes in the field of Machine Learning, where, in general, we start with set of training observations, $X$ along with a response variable $y$ and we try to find a Machine Learning model, which is just a function $f(X, \\theta)$ depending on certain parameters $\\theta$, that tries to approximate $y$ as best as possible.\n",
    "\n",
    "These are known as **supervised** problems, because we have a set of true responses, $y$ for our training data. The task here is to find the parameters $\\theta$ that minimize our 'error', which is the difference between $f(X,\\theta)$ and $y$ (in the literature, this error is computed with an extra function called a **loss function**). As you can see, minimizing the error function is crucial to train a meaningful Machine Learning model. And this is only an example of the need to minimize a target function, there are other fields such as Finance or Economics where minima localization algorithms are needed.\n",
    "\n",
    "So, finding function minima seems to be very important, but, how to we find these minima for functions in general? If you recall from Calculus the local minima of a function are attained where the gradient of this function equals zero. In practice, finding gradients and their zeros might become tedious and inpractical for higher dimensions (as we will see below), and it turns out there is a much faster and clever algorithm to find these minima, called **Gradient Descent**. We will study the basics of this algorithm and its variants in this section, as well as provide some examples of how to apply it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jimmycalvomonge.github.io/appmathpython/_static/gradient.png\" alt=\"gradient\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "Here are some extra resources you can find in the web that talk about this topic. \\\n",
    "*These links are external and we don't take responsibility for any downtime or incovenient caused by them.*\n",
    "\n",
    "- [Utah Gradient Descent notes](https://users.cs.utah.edu/~jeffp/IDABook/T6-GD.pdf)\n",
    "- [Real Python: Stochastic Gradient Descent Algorithm With Python and NumPy](https://realpython.com/gradient-descent-algorithm-python/)\n",
    "- [Stat Quest Gradient Descent](https://www.youtube.com/watch?v=sDv4f4s2SB8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's review the theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other variants of gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
